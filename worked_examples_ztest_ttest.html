<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Worked examples</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/ninjutsu.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Worked examples
## One proportion z test, and One sample t test

---




class: inverse, center, middle

# Part I: Proportions

--

## This part is about when there are two outcomes.


---

## Consider the observed data for survivorship data of female passengers on the Titanic:

--







| Female|survived |
|------:|:--------|
|    126|No       |
|    344|Yes      |

--

## Does this outcome differ from an underlying process where probability of surviving is 50/50 (proportion = .5)?


---
class: inverse, center, middle

# Step 1: Collecting the basic facts of the question


---

### What is the name of the theory-based test we should use?

--

### *One proportion Z Test*

--

### What are our Hypotheses?

--

### $$ H_0: \Pi = .5 $$

--

### Which implies

### $$ H_A: \Pi \neq  .5 $$  
--

### but we know other inequalites (&gt;, &lt;) are possible;


---

## Cautions on hypothesis statements:


### 1. reread question to verify you got the right inequality
--

### 2. remember to use Greek letters for these proposed *parameters*!  'hypothesis' has a greek etymology, this is the weighty, long run or population proposal
--

### 3 a common mistake is to write 'H = ...' 
--
But we actually use colons to introduce the hypothesis 'Ho: ...' 
 

---


---

# Now let's also summarize the basic facts of this case in code and save objects in the R environment (n, phat, and pi)


---

count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries-auto[

```r
# sample size
*126 + 344
```
]
 
.panel2-preliminaries-auto[

```
## [1] 470
```
]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries-auto[

```r
# sample size
126 + 344 -&gt;
* n
```
]
 
.panel2-preliminaries-auto[

]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries-auto[

```r
# sample size
126 + 344 -&gt;
  n

# observed proportion
*344/n
```
]
 
.panel2-preliminaries-auto[

```
## [1] 0.7319149
```
]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries-auto[

```r
# sample size
126 + 344 -&gt;
  n

# observed proportion
344/n -&gt;
* phat
```
]
 
.panel2-preliminaries-auto[

]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries-auto[

```r
# sample size
126 + 344 -&gt;
  n

# observed proportion
344/n -&gt;
  phat

# proposed parameter
*.5
```
]
 
.panel2-preliminaries-auto[

```
## [1] 0.5
```
]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries-auto[

```r
# sample size
126 + 344 -&gt;
  n

# observed proportion
344/n -&gt;
  phat

# proposed parameter
.5 -&gt;
* Pi
```
]
 
.panel2-preliminaries-auto[

]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries-auto[

```r
# sample size
126 + 344 -&gt;
  n

# observed proportion
344/n -&gt;
  phat

# proposed parameter
.5 -&gt;
  Pi
```
]
 
.panel2-preliminaries-auto[

]

&lt;style&gt;
.panel1-preliminaries-auto {
  color: black;
  width: 38.6060606060606%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel2-preliminaries-auto {
  color: black;
  width: 59.3939393939394%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel3-preliminaries-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
class: inverse, center, middle

# Step 2. How far am I into the tails of the null distribution?  
--
Calculating the standardized statistic  
--
(Z in this case)




---

### Okay. Let's look at *calculating* the test statistic: Z

--

### (i.e. how far in the null distribution are we out in standard deviations?)

--

##  $$ Z = \frac{\hat{p}-\Pi}{SD_{null}}$$
--
where

## $$ SD_{null} = \sqrt{\frac{\Pi*(1-\Pi)}{n}}$$







---

count: false
 

.panel1-standardized-auto[

```r
# lets just compute the numerator
*phat - Pi
```
]
 
.panel2-standardized-auto[

```
## [1] 0.2319149
```
]

---
count: false
 

.panel1-standardized-auto[

```r
# lets just compute the numerator
phat - Pi -&gt;
* z_numerator
```
]
 
.panel2-standardized-auto[

]

---
count: false
 

.panel1-standardized-auto[

```r
# lets just compute the numerator
phat - Pi -&gt;
  z_numerator

# and now the denominator
*sqrt(Pi*(1-Pi)/n)
```
]
 
.panel2-standardized-auto[

```
## [1] 0.02306328
```
]

---
count: false
 

.panel1-standardized-auto[

```r
# lets just compute the numerator
phat - Pi -&gt;
  z_numerator

# and now the denominator
sqrt(Pi*(1-Pi)/n) -&gt;
* sd_null
```
]
 
.panel2-standardized-auto[

]

---
count: false
 

.panel1-standardized-auto[

```r
# lets just compute the numerator
phat - Pi -&gt;
  z_numerator

# and now the denominator
sqrt(Pi*(1-Pi)/n) -&gt;
  sd_null

# and combining
*z_numerator/sd_null
```
]
 
.panel2-standardized-auto[

```
## [1] 10.05559
```
]

---
count: false
 

.panel1-standardized-auto[

```r
# lets just compute the numerator
phat - Pi -&gt;
  z_numerator

# and now the denominator
sqrt(Pi*(1-Pi)/n) -&gt;
  sd_null

# and combining
z_numerator/sd_null -&gt;
* z
```
]
 
.panel2-standardized-auto[

]

&lt;style&gt;
.panel1-standardized-auto {
  color: black;
  width: 38.6060606060606%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel2-standardized-auto {
  color: black;
  width: 59.3939393939394%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel3-standardized-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;







---

&lt;img src="worked_examples_ztest_ttest_files/figure-html/unnamed-chunk-3-1.png" width="80%" /&gt;

--

## So I'm way out in the tail of that null distribution.




---
class: inverse, center, middle


# Step 3: Express this extremeness as a p-value.
--

### In other words, how likely am I to observe something as extreme or more extreme than my statistic (phat in this case), if the null is true;  
--
p-value expresses this as a proportion (logical max 1 - totally consistent w/ null; logical min 0 -- totally inconsistent with null);   
--
The smaller the p-value, the more inconsistent w/ the null.  
--
This is also the area under the tails of the distribution of the null.


---

### Calculating the p-value depends on Z and which inequality I used in my hypotheses set up.  
--
I know I'll use the function pnorm(),
--
and choose from the code based on my alternative hypothesis:

--

|Alternative Hypothesis|R Code|
|:--------------------:|------|
|$$ &gt; $$|`1-pnorm(z)`|
|$$ &lt; $$|`pnorm(z)`|
|$$ \neq$$|`2*(1-pnorm(abs(z)))`|


---

## I'll use the two-tailed test; after double checking the question wording: "Does this outcome *differ...*".

--

## So...


```r
2*(1-pnorm(abs(z)))
```

```
## [1] 0
```

--

### The p-value output is computationally zero!  

--

### So my observed value p-hat, 0.73, is quite inconsistent with the null.

--

### There is very strong evidence against the null hypothesis.



---
class: inverse, center, middle

# Step 4. What are plausible values of the parameter?


--
### The confidence interval?
--
what are values that are consistent with the observed statistic?
--


---

### I want to look at the interval centered around p-hat, that will contain Pi 95% (or sometimes 90% or 99%) of the time in repeated samples.

### So I'm picturing a normal distribution centered at p-hat, and an interval under that, which when integrated encompasses 95% of the area...

---



&lt;img src="worked_examples_ztest_ttest_files/figure-html/unnamed-chunk-5-1.png" width="70%" /&gt;

---
## The confidence interval is:

# $$ phat \pm M*SE   $$
--

### where:

### M, the multiplier, is determined by the significance level that's desired; 
--
95, 99 or 90 are common.

--
### and where:

$$ SE = \sqrt{\frac{\hat{p}*(1-\hat{p})}{n}} $$


---


## So, I look up the *R code* needed for M in this table.
--


|**Confidence Level**|**Multiplier (Categorical)**|**Multiplier (Quantitative)**|
|-------------------|-----------------------|-------------------------|
|90%|qnorm(.95)| qt(.95,n-1) or qt(.95,n-2)|
|95%|qnorm(.975)|qt(.975,n-1) or qt(.975,n-2)|
|99%|qnorm(.995)|qt(.995,n-1) or qt(.995,n-2)|

---

### and then I compute the lower bound



```r
m = qnorm(.975)
se = sqrt(phat*(1-phat)/n)

phat - m*se
```

```
## [1] 0.6918683
```

### and the upper bound


```r
phat - m*se
```

```
## [1] 0.6918683
```

---

# Note

--

## The 'margin of error' is a special case where the multiplier is equal to 2


```r
margin_of_error = 2 * se
```


---

# Step 5. Celebrate! You're done!!

---

# Step 6. Practice

---

### What if I had asked about survivorship for children on the titanic differing from .5.





---



---

class: inverse, center, middle

# Part II: *Means* (average) of quantitative variable

--

## This part deals with *continuous* (numeric, multi values) data.





---

## Consider chicks weight at 6 weeks.  You know a chicken farmer and she asserts that chicks will weigh 250 grams on average at six weeks.

--

but you visit a farm and collect some data and you think that chicks actually might weigh more than the proposed 250 grams on average.
--

See the summary of `chickwts` on the next slide.  

---


```r
library(skimr)
skim(chickwts)
```

```
Skim summary statistics
 n obs: 71 
 n variables: 2 
 group variables:  

── Variable type:factor ────────────────────────────────────────────────────────
 variable missing complete  n n_unique                         top_counts
     feed       0       71 71        6 soy: 14, cas: 12, lin: 12, sun: 12
 ordered
   FALSE

── Variable type:numeric ───────────────────────────────────────────────────────
 variable missing complete  n   mean    sd  p0   p25 p50   p75 p100     hist
   weight       0       71 71 261.31 78.07 108 204.5 258 323.5  423 ▃▅▅▇▃▇▂▂
```

---

![](worked_examples_ztest_ttest_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;


---
class: inverse, center, middle

# Step 1: Collecting the basic facts of the question


---

## What is the name of the theory-based test we should use?

--

*One sample t-test*

--

## What are our Hypotheses?

--

 $$ H_0: \mu = 150 grams $$

--

### Which implies

 $$ H_A: \mu &gt;  150 grams $$  
--

### but we know other inequalites are possible;
--
reread question to verify you got the right one
--
 



--

## Is there evidence that the weight time will actually average more than an 150 grams at 6 weeks?




---

# Now let's also summarize the basic facts of this case in code and save objects in the R environment (n, phat, and pi)


---

count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
*250
```
]
 
.panel2-preliminaries2-auto[

```
## [1] 250
```
]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
250 -&gt;
* mu
```
]
 
.panel2-preliminaries2-auto[

]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
250 -&gt;
  mu

# sample size
*71
```
]
 
.panel2-preliminaries2-auto[

```
## [1] 71
```
]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
250 -&gt;
  mu

# sample size
71 -&gt;
* n
```
]
 
.panel2-preliminaries2-auto[

]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
250 -&gt;
  mu

# sample size
71 -&gt;
  n

# observed mean 261 grams
*261.31
```
]
 
.panel2-preliminaries2-auto[

```
## [1] 261.31
```
]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
250 -&gt;
  mu

# sample size
71 -&gt;
  n

# observed mean 261 grams
261.31 -&gt;
* xbar
```
]
 
.panel2-preliminaries2-auto[

]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
250 -&gt;
  mu

# sample size
71 -&gt;
  n

# observed mean 261 grams
261.31 -&gt;
  xbar

# the sample standard deviation is
*78.07
```
]
 
.panel2-preliminaries2-auto[

```
## [1] 78.07
```
]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
250 -&gt;
  mu

# sample size
71 -&gt;
  n

# observed mean 261 grams
261.31 -&gt;
  xbar

# the sample standard deviation is
78.07 -&gt;
* s
```
]
 
.panel2-preliminaries2-auto[

]

---
count: false
 
## The basic facts, recorded as R objects
.panel1-preliminaries2-auto[

```r
# proposed parameter
# mu a mean of 250 grams
250 -&gt;
  mu

# sample size
71 -&gt;
  n

# observed mean 261 grams
261.31 -&gt;
  xbar

# the sample standard deviation is
78.07 -&gt;
  s
```
]
 
.panel2-preliminaries2-auto[

]

&lt;style&gt;
.panel1-preliminaries2-auto {
  color: black;
  width: 38.6060606060606%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel2-preliminaries2-auto {
  color: black;
  width: 59.3939393939394%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel3-preliminaries2-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;





---
class: inverse, center, middle

# Step 2. How far am I into the tails of the null distribution?
--
Calculating the standardized statistic
--
(t in this case)




---

### Okay. Let's look at *calculating* the test statistic: t

--

### (i.e. how far in the null distribution are we out in standard deviations?)

--

##  $$ Z = \frac{\bar{x}-\mu}{SD_{null}}$$
--
where

## $$ SD_{null} = \frac{s}{\sqrt{n}}$$







---

count: false
 

.panel1-standardized2-auto[

```r
# lets just compute the numerator
*xbar - mu
```
]
 
.panel2-standardized2-auto[

```
## [1] 11.31
```
]

---
count: false
 

.panel1-standardized2-auto[

```r
# lets just compute the numerator
xbar - mu -&gt;
* t_numerator
```
]
 
.panel2-standardized2-auto[

]

---
count: false
 

.panel1-standardized2-auto[

```r
# lets just compute the numerator
xbar - mu -&gt;
  t_numerator

# and now the denominator
*s/sqrt(n)
```
]
 
.panel2-standardized2-auto[

```
## [1] 9.265204
```
]

---
count: false
 

.panel1-standardized2-auto[

```r
# lets just compute the numerator
xbar - mu -&gt;
  t_numerator

# and now the denominator
s/sqrt(n) -&gt;
* sd_null
```
]
 
.panel2-standardized2-auto[

]

---
count: false
 

.panel1-standardized2-auto[

```r
# lets just compute the numerator
xbar - mu -&gt;
  t_numerator

# and now the denominator
s/sqrt(n) -&gt;
  sd_null

# and combining
*t_numerator/sd_null
```
]
 
.panel2-standardized2-auto[

```
## [1] 1.220696
```
]

---
count: false
 

.panel1-standardized2-auto[

```r
# lets just compute the numerator
xbar - mu -&gt;
  t_numerator

# and now the denominator
s/sqrt(n) -&gt;
  sd_null

# and combining
t_numerator/sd_null -&gt;
* t
```
]
 
.panel2-standardized2-auto[

]

&lt;style&gt;
.panel1-standardized2-auto {
  color: black;
  width: 38.6060606060606%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel2-standardized2-auto {
  color: black;
  width: 59.3939393939394%;
  hight: 32%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
.panel3-standardized2-auto {
  color: black;
  width: NA%;
  hight: 33%;
  float: left;
  padding-left: 1%;
  font-size: 80%
}
&lt;/style&gt;







---

So what I'm picturing is...

--


```r
ggplot(chickwts) +
  geom_vline(xintercept = mu,
             linetype = "dashed",
             color = "cadetblue") +
  ggxmean:::stamp_normal_dist(sd = sd_null,
                              mean = mu,
                              alpha = .5,
                              fill = "cadetblue",
                              height = 5, size =2) +
  NULL
```

--

So I'm way out in the tail of that null distribution.




---
class: inverse, center, middle


# Step 3: Express this extremeness as a p-value.
--

### In other words, how likely am I to observe something as extreme or more extreme than my statistic (x-bar in this case), if the null is true;
--
p-value expresses this as a proportion (logical max 1 - totally consistent w/ null; logical min 0 -- totally inconsistent with null);  
--
The smaller the p-value, the more inconsistent w/ the null.


---

### Calculating the p-value depends on t and which inequality I used in my hypotheses set up.  
--
I know I'll use the function pt(),
--
and choose from the code based on my alternative hypothesis:

--

|Alternative Hypothesis|R Code|
|:--------------------:|------|
|$$ &gt; $$|`1-pt(t, df = n-1)`|
|$$ &lt; $$|`pt(t, df = n-1)`|
|$$ \neq$$|`2*(1-pt(abs(t), df = n-1))`|


---

## I'll use the greater than test; after double checking the question wording: "Is the weight greater than...".

--

## So...


```r
1 - pt(t, df = n-1)
```

```
## [1] 0.1131485
```

--

### The p-value output is 0.1131485; this is *not* a very small proportion of times.  

--

### So my observed value p-hat, 261.31, is consistent with the null.  

--

### There is little evidence against the null.

--



---
class: inverse, center, middle

# Step 4. What are plausible values of the parameter?


--
### The confidence interval?
--
what are values that are consistent with the observed statistic?
--


---

### I want to look at the interval centered around xbar, that will contain $ \Pi $ 95% (or sometimes 90% or 99%) of the time in repeated samples.

---

## So I'm picturing a distribution is centered around my observed statistic xbar
-- 
and want to know the interval under that, which when integrated encompasses 95% of the area
--
also centered around xbar




```r
library(ggstamp)
c(rep(0, 126), rep(1, 344)) -&gt; x

ggcanvas() +
  scale_x_continuous(limits = 0:1) +
  geom_vline(xintercept = 0:1, linetype = "dotted") +
  geom_vline(xintercept = Pi,
             linetype = "dashed") +
  geom_vline(xintercept = phat) +
  ggxmean:::geom_ttestconf(data = tibble(x = x),
                           aes(x = x),
                           color = "darkred",
                           size = 3) +
  ggxmean:::geom_tdist(data = tibble(x = x),
                           aes(x = x),
                           fill = "goldenrod3",
                       height = .45) +
  NULL
```

---
## The confidence interval is:

# $$ \bar{x} \pm M*SE   $$
--

### where:

### M, the multiplier, is determined by the significance level that's desired; 95, 99 or 90 are common.

--
### and where:

$$ SE = \frac{s}{\sqrt{n}} $$


---


## So, I look up the *R code* needed for M in this table.
--


|**Confidence Interval**|**Multiplier (Categorical)**|**Multiplier (Quantitative)**|
|-------------------|-----------------------|-------------------------|
|90%|qnorm(.95)| qt(.95,n-1) or qt(.95,n-2)|
|95%|qnorm(.975)|qt(.975,n-1) or qt(.975,n-2)|
|99%|qnorm(.995)|qt(.995,n-1) or qt(.995,n-2)|

---

### and compute the lower bound



```r
se = s/sqrt(n)
m = qt(.975, df = n - 1)
margin_of_error = se*m

xbar - margin_of_error
```

```
## [1] 242.8311
```

--

### and the upper bound


```r
xbar + margin_of_error
```

```
## [1] 279.7889
```


---

# Step 5. Celebrate! You're done!!

---

# Step 6. Practice

---

### What if I had asked about length of the erruption time itself?


---

## Consider the wait time between each erruption blast of the Old Faithful Geysers
https://www.yellowstonepark.com/things-to-do/geysers-hot-springs/about-old-faithful/:

--

You are visiting the park, and want to know how long you will have to wait between each eruption.

--

A friend tells you it will be on average an hour between each eruption.

--

But you have some data on wait times, and you want to know if it will take *more* than an hour.

---


```r
library(skimr)
skim(faithful)
```

```
## Skim summary statistics
##  n obs: 272 
##  n variables: 2 
##  group variables:  
## 
## ── Variable type:numeric ───────────────────────────────────────────────────────
##   variable missing complete   n  mean    sd   p0   p25 p50   p75 p100     hist
##  eruptions       0      272 272  3.49  1.14  1.6  2.16   4  4.45  5.1 ▇▃▁▁▂▅▇▃
##    waiting       0      272 272 70.9  13.59 43   58     76 82    96   ▂▅▃▂▅▇▆▂
```


---


```r
# basic facts
xbar = 70.9
s = 13.6
n = 272

mu = 60
```


```r
# calculating t
t_numerator = xbar - mu  
se = s / (sqrt(n)) # the denominator
t = t_numerator / se
```


---


```r
# calculating the pvalue.
# correct code depends on 
# the alternative hypothesis
# consult chart
1-pt(t, df= n - 1)
```

```
## [1] 0
```



```r
# calculating the confidence interval
# correct code depends on 
# the alternative hypothesis
multiplier = qt(.975, n-1)
se = s / (sqrt(n))
margin_of_error = multiplier*se

xbar - margin_of_error
```

```
## [1] 69.27652
```

```r
xbar + margin_of_error
```

```
## [1] 72.52348
```



---





&lt;!-- adjust font size in this css code chunk, currently 80 --&gt;

&lt;style type="text/css"&gt;
.remark-code{line-height: 1.5; font-size: 120%}

@media print {
  .has-continuation {
    display: block;
  }
}

code.r.hljs.remark-code{
  position: relative;
  overflow-x: hidden;
}


code.r.hljs.remark-code:hover{
  overflow-x:visible;
  width: 500px;
  border-style: solid;
}
&lt;/style&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
